{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14lT_SrMTPDKZP2qSvfWMdihDaDFF4Fhm",
      "authorship_tag": "ABX9TyP0qRDwKnewiovSXICMgJ+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HS587885/Studying-MachineLearning/blob/main/Tensorflow_imageclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_VCvXIcfndf9"
      },
      "outputs": [],
      "source": [
        "# 초기코드 - python\n",
        "from keras import utils\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,ZeroPadding2D,GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from keras.models import load_model\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.layers import Activation, Dense\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/drive/MyDrive/data/view_data/seg_pred.zip\n",
        "# !unzip /content/drive/MyDrive/data/view_data/seg_train.zip\n",
        "# !unzip /content/drive/MyDrive/data/view_data/seg_test.zip\n",
        "\n",
        "!unzip /content/drive/MyDrive/data/cats_dogs.zip"
      ],
      "metadata": {
        "id": "skGbg2bgqEG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/view_data'\n",
        "#test_data_dir = '/content/seg_test'\n",
        "\n",
        "img_height=260\n",
        "img_width=260\n",
        "batch_size=32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    zoom_range=0.4,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=(0.9,1.1),\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,\n",
        "     validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    interpolation='lanczos',\n",
        "    shuffle=True,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    interpolation='lanczos',\n",
        "    shuffle=False,\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "\n",
        "effi = EfficientNetB2(include_top=False, input_shape=(260,260,3))\n",
        "model=Sequential()\n",
        "model.add(effi)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# model = EfficientNetB4(include_top=True, input_shape=(380,380,3))\n",
        "# model.summary()\n",
        "# 새 섹션\n",
        "#optimizer = SGD(lr=1e-4, momentum=0.9)\n",
        "#optimizer RMSprop(lr=2e-5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_dir = './model'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "model_path = model_dir + '/efficientnetB2_dropout12.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
        "nb_epochs=50\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    callbacks=[checkpoint,early_stopping]\n",
        "    )\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_csv_file = 'history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "!cp history.csv /content/history.csv\n",
        "!cp -r model /content/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNAmayQ8nnay",
        "outputId": "a6a6a356-ce06-479c-8869-21e926f98ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb2 (Functional  (None, 9, 9, 1408)        7768569   \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 1408)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1408)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 2818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7771387 (29.65 MB)\n",
            "Trainable params: 7703812 (29.39 MB)\n",
            "Non-trainable params: 67575 (263.97 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/50 [===========>..................] - ETA: 9:30 - loss: 0.2886 - accuracy: 0.8766"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V96WHUeGt5vi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}